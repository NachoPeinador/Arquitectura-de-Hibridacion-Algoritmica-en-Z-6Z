\documentclass[12pt, a4paper]{article}

% --- PACKAGES AND CONFIGURATION ---
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath, amssymb, amsthm, amsfonts}
\usepackage{mathptmx} % Times font (Academic standard)
\usepackage[margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs} % Professional tables
\usepackage{enumitem}
\usepackage{float}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{orcidlink}
\usepackage{cite}
\usepackage{tabularx}
\usepackage{multirow}

% Hyperlink configuration (sober academic colors)
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=teal,
    citecolor=blue,
}

% --- HEADER AND FOOTER CONFIGURATION ---
\pagestyle{fancy}
\fancyhf{}
\rhead{\small The Modular Spectrum of $\pi$}
\lhead{\small Peinador Sala}
\cfoot{\thepage}

% --- ENVIRONMENT DEFINITIONS ---
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

% --- DOCUMENT METADATA ---
\title{\textbf{The Modular Spectrum of $\pi$: Theoretical Unification, DSP Isomorphism, and Exascale Validation}\\
\large Algorithmic Hybridization Architecture in $\mathbb{Z}/6\mathbb{Z}$}

\author{
  \textbf{José Ignacio Peinador Sala}\orcidlink{0009-0008-1822-3452} \\
  \textit{Independent Researcher} \\
  \href{mailto:joseignacio.peinador@gmail.com}{joseignacio.peinador@gmail.com}
}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This article presents the definitive consolidation of the \textbf{Modular Spectrum} theoretical framework, which resolves the apparent discontinuity between the discrete nature of integers $\mathbb{Z}$ and the transcendental periodicity of trigonometric functions through a decomposition based on the ring $\mathbb{Z}/6\mathbb{Z}$. A formal \textbf{isomorphism} is demonstrated between this arithmetic structure and \textbf{Polyphase Decomposition} used in Digital Signal Processing (DSP). This isomorphism is not merely an analogy but a mathematical equivalence that allows reinterpretation of hypergeometric series calculation as a multirate filtering problem. The study culminates with the implementation and experimental validation of the \textbf{Hybrid Stride-6 Architecture}, a \textit{Shared-Nothing} design that calculates $10^8$ digits of $\pi$ in a resource-constrained environment (12GB RAM) with 95\% parallelization efficiency and a sustained speed of 83,000 digits/s, challenging the \textit{Memory Wall} of monolithic algorithms. Finally, the modular filter is applied to the study of non-trivial zeros of the Riemann Zeta function, confirming their \textbf{spectral rigidity} and absence of simple arithmetic biases, consistent with predictions of the \textit{Gaussian Unitary Ensemble} (GUE). The work merges number theory, high-performance software engineering, and quantum chaos physics, proposing a new paradigm for extreme-precision computation.
\end{abstract}

% ----------------------------------------------------------------------
\section{Introduction: From Calculation to Structure}
% ----------------------------------------------------------------------

The calculation of transcendental constants, particularly $\pi$, has historically served as the supreme \textit{benchmark} for measuring raw power, numerical stability, and the evolution of computational systems. From iterative algorithms of antiquity to modern rapidly converging hypergeometric series, the implicit goal has been linear: to generate digits sequentially, faster and faster \cite{chudnovsky}. However, this approach collides with a fundamental barrier that transcends the computational and enters the epistemological: the unresolved tension between the \textbf{discrete} (the domain $\mathbb{Z}$ of indices, finite machine operations) and the \textbf{continuous/transcendental} (the geometric and irrational nature of $\pi$, the $2\pi$ periodicity of harmonic functions). We call this tension \textbf{the Continuum Crisis in Numerical Computation}.

Evaluating functions like $\sin(n)$ for $n \in \mathbb{Z}$ generates an apparently chaotic sequence, resulting from the incommensurability between the integer lattice and the period $2\pi$. Traditionally, this "chaos" is managed as inevitable noise. This work posits the opposite: the chaos is apparent and emerges from a suboptimal sampling structure. The central proposal is that the number line $\mathbb{Z}$, when observed through the \textbf{modular filter} $m=6$, reveals a deep, computationally exploitable order.

The choice of $m=6$ is not arbitrary. It is the product of the first two primes ($2 \times 3$) and is intimately linked to the structure of the \textbf{hexagonal lattice} $A_2$, the densest arrangement for packing circles in the plane \cite{conway1999sphere}. This geometric connection suggests that $m=6$ captures fundamental rotational symmetries that other moduli (such as $4$ or $8$) lose. By projecting the Chudnovsky series \cite{chudnovsky} onto residues modulo $6$, we not only decompose the computational problem but \textbf{align the arithmetic sampling with the intrinsic geometry of the problem}.

Beyond optimization, this approach reveals a formal \textbf{isomorphism} with the theory of \textit{multirate} filter banks in DSP \cite{vaidyanathan}. The "modular channels" of residues $r \in \{0,1,2,3,4,5\}$ are mathematically equivalent to the \textbf{polyphase components} of a decimated signal. This equivalence transforms a number theory problem into a signal processing problem, endowing it with an arsenal of proven techniques for analysis, synthesis, and efficient implementation.

This article consolidates and expands previous work \cite{peinador}, structured around three interconnected pillars:
\begin{enumerate}[label=(\textbf{\Roman*})]
    \item \textbf{Theoretical Foundations:} Formalization of the polyphase isomorphism in $\mathbb{Z}/6\mathbb{Z}$, its connection with Eisenstein integers, and the role of channel $r=3$ as a "stability attractor" linked to Euler's identity.
    \item \textbf{Computational Architecture:} Design, implementation, and comprehensive validation of the \textbf{Hybrid Stride-6} algorithm, a \textit{Shared-Nothing} architecture that eliminates memory bottlenecks and scales nearly linearly in constrained parallel environments.
    \item \textbf{Physical-Mathematical Implications:} Application of the modular filter to the study of Riemann zeros, confirming their uniform distribution modulo $6$ as a manifestation of spectral rigidity and absence of simple arithmetic structure, in line with quantum chaos conjectures \cite{odlyzko}.
\end{enumerate}

The result is a unified framework that not only provides a superior algorithm for calculating $\pi$, but also offers a new lens through which to observe the interface between the discrete and the continuous, with ramifications in number theory, systems engineering, and theoretical physics.

% ----------------------------------------------------------------------
\section{Theoretical Foundations: The \texorpdfstring{$\mathbb{Z}/6\mathbb{Z}$}{Z/6Z} Filter and the Polyphase Isomorphism}
% ----------------------------------------------------------------------

\subsection{The Choice of Modulus 6: From Arithmetic to Geometry}
The choice of modulus $m=6$ as the core of the modular spectrum is based on a unique conjunction of arithmetic, algebraic, and geometric properties that distinguish it as an optimal filter for analyzing numerical series with underlying rotational symmetry.

\begin{definition}[Standard Modular Decomposition]
For any discrete angle $\theta = n \in \mathbb{Z}$, we define its canonical decomposition modulo 6 via the division algorithm:
\begin{equation}
n = 6k + r, \quad \text{where } k \in \mathbb{Z} \text{ and } r \in R_6 = \{0,1,2,3,4,5\}.
\end{equation}
This transformation establishes an isomorphism of $\mathbb{Z}$-modules:
\begin{equation}
\mathbb{Z} \cong \mathbb{Z} \times \mathbb{Z}/6\mathbb{Z},
\end{equation}
mapping the one-dimensional number line to a discrete cylinder whose fiber is the cyclic ring of order 6.
\end{definition}

The functional classification of residues, beyond parity, reveals their structural role:
\begin{itemize}
    \item \textbf{Null Channels ($r=0,3$):} Correspond to zero divisors in $\mathbb{Z}/6\mathbb{Z}$ ($\gcd(r,6) \neq 1$). Channel $r=3$ is particularly significant, acting as a \textbf{stability attractor} because $3$ is the closest integer approximation to $\pi$.
    \item \textbf{Prime Channels ($r=1,5$):} Form the multiplicative group $(\mathbb{Z}/6\mathbb{Z})^\times = \{1,5\}$, of order $\varphi(6)=2$. They are the arithmetic generators, associated with "high-frequency" information in the spectral analogy.
    \item \textbf{Composite Channels ($r=2,4$):} Share the prime factor $2$ with the modulus. They exhibit mirror symmetries ($4 \equiv -2 \mod 6$) and represent even harmonics within the structure.
\end{itemize}

The deep geometric connection emerges by identifying $\mathbb{Z}/6\mathbb{Z}$ with the \textbf{sixth roots of unity} $e^{2\pi i r/6}$, which form the vertices of a regular hexagon in the complex plane. This hexagon is the fundamental cell of the \textbf{hexagonal lattice} $A_2$, the two-dimensional lattice with the highest circle packing density \cite{conway1999sphere}. Thus, the modular filter not only classifies integers but \textbf{projects the one-dimensional sequence of indices onto the optimal packing structure in the plane}, revealing a geometric order underlying the apparent randomness of discrete evaluations of transcendental functions.

\subsection{The \texorpdfstring{$r=3$}{r=3} Attractor and the Discretized Euler Identity}
Euler's identity, $e^{i\pi} + 1 = 0$, represents the culmination of the synthesis between algebra, analysis, and geometry. Under the modular filter, we find a fascinating discrete and approximate version that sheds light on its numerical stability.

Since $\pi \approx 3.14159$, the closest integer is $3$. In the modular scheme, $\pi$ (in radians) is mapped to residue $3$ when considering the full turn $2\pi \equiv 6$. We evaluate the position on the unit circle corresponding to this "discrete attractor":
\begin{equation}
e^{i3} = \cos(3) + i\sin(3) \approx -0.9899924966 + 0.1411200081i.
\end{equation}
This vector has a norm very close to 1 and an argument very close to $\pi$ radians. Its proximity to the point $-1$ (absolute error $\approx 0.0100075$) suggests that Euler's identity \textbf{leverages a natural stability point in the hexagonal lattice} defined by the sixth roots of unity. The $r=3$ channel thus serves as a geometric anchor that minimizes phase fluctuation in partial sums of alternating series, providing a structural basis for numerical convergence.

\subsection{Formal Isomorphism with Polyphase Decomposition (DSP)}
The central theoretical contribution of this work is the formalization of an isomorphism between the modular decomposition of hypergeometric series and the polyphase decomposition of discrete signals in Digital Signal Processing (DSP). This bridge is not merely metaphorical but a precise mathematical result that allows transferring mature filter design techniques to the domain of high-precision computation.

\begin{theorem}[Polyphase Isomorphism]
Let $S = \sum_{n=0}^{\infty} a_n$ be a convergent series of complex terms (e.g., the terms of the Chudnovsky series for $1/\pi$). Let $M=6$ be the decimation factor. The modular decomposition of $S$ into $M$ sub-series,
\begin{equation}
S_r = \sum_{k=0}^{\infty} a_{Mk + r}, \quad r \in R_M,
\end{equation}
is mathematically equivalent to the polyphase decomposition of a discrete signal $x[n] := a_n$ in the Z-domain.
\end{theorem}

\begin{proof}[Proof Sketch]
Consider the discrete signal $x[n] = a_n$ for $n \geq 0$. Its unilateral Z-Transform is $X(z) = \sum_{n=0}^{\infty} a_n z^{-n}$. Applying a polyphase decomposition with factor $M$, $X(z)$ is expressed as:
\begin{equation}
X(z) = \sum_{r=0}^{M-1} z^{-r} E_r(z^M),
\end{equation}
where the \textbf{polyphase components} $E_r(z)$ are defined by:
\begin{equation}
E_r(z) = \sum_{k=0}^{\infty} a_{Mk + r} z^{-k}.
\end{equation}
Evaluating at $z=1$ (which corresponds to the total sum of the series), we obtain:
\begin{equation}
E_r(1) = \sum_{k=0}^{\infty} a_{Mk + r} = S_r.
\end{equation}
Therefore, the vector of modular partial sums $(S_0, S_1, \dots, S_{M-1})$ is exactly the vector of evaluations $(E_0(1), E_1(1), \dots, E_{M-1}(1))$ of the polyphase components. Reconstruction of the original series is achieved by summation:
\begin{equation}
S = \sum_{r=0}^{M-1} S_r = \sum_{r=0}^{M-1} E_r(1) = X(1),
\end{equation}
which establishes the isomorphism. The orthogonality of the channels in the time domain (non-overlapping indices) guarantees no "leakage" of information between sub-bands, analogous to a perfect reconstruction filter bank.
\end{proof}

Table \ref{tab:isomorphism} summarizes the correspondence of concepts between the two domains.

\begin{table}[H]
\centering
\caption{Concept Correspondence in the Polyphase Isomorphism ($M=6$)}
\label{tab:isomorphism}
\begin{tabularx}{\linewidth}{>{\raggedright\arraybackslash}X >{\raggedright\arraybackslash}X}
\toprule
\textbf{Number Theory / $\pi$ Calculation} & \textbf{Digital Signal Processing} \\
\midrule
Hypergeometric series $S = \sum a_n$ & Discrete signal $x[n] = a_n$ \\
Integer index $n \in \mathbb{Z}$ & Discrete time $n$ \\
Modulo $m=6$ decomposition: $n = 6k + r$ & Decimation by factor $M=6$ with phase $r$ \\
Modular sub-series $S_r = \sum_k a_{6k+r}$ & Polyphase component $E_r(z) = \sum_k x[6k+r] z^{-k}$ \\
Modular channel (residue $r$) & Filter sub-band (branch $r$ of the bank) \\
Reconstruction: $S = \sum_{r=0}^{5} S_r$ & Interpolation: $X(z) = \sum_{r=0}^{5} z^{-r} E_r(z^6)$ \\
Orthogonality: disjoint indices & Orthogonality: perfect reconstruction filter banks \\
\bottomrule
\end{tabularx}
\end{table}

\subsection{Implications of the Isomorphism for Computation}
This isomorphism has immediate and profound practical consequences:
\begin{enumerate}
    \item \textbf{Embarrassingly Parallel Parallelization:} The independence of the polyphase components $E_r(z)$ translates to the independence of the sub-series $S_r$. This allows calculating each channel in separate processes, without intermediate communication or synchronization—the essence of a \textit{Shared-Nothing} architecture.
    \item \textbf{Reduction of Operational Complexity:} In DSP, processing after decimation (over indices $k$) reduces the data rate. Computationally, this means the most expensive arithmetic operations are performed on a sequence 6 times shorter, reducing recursion tree depth and operand magnitude in early stages.
    \item \textbf{Energy/Information Conservation:} A perfect reconstruction polyphase filter bank guarantees no information loss. In our context, this is verified experimentally by checking that the sum of modular contributions recovers exactly the original series, with negligible numerical error (\textit{round-off}).
\end{enumerate}

The isomorphism thus not only justifies the modular approach but endows it with a robust, transferable theoretical framework, opening the door to applying decades of filter theory advances to the challenge of extreme-precision computation.

% ----------------------------------------------------------------------
\section{Computational Architecture: Hybrid Stride-6 and Overcoming the ``Memory Wall''}
% ----------------------------------------------------------------------

\subsection{The Fundamental Problem: Monolithic Parallelization vs. Memory Wall}
Modern algorithms for calculating $\pi$, such as the implementation of \textit{Binary Splitting} on the Chudnovsky series \cite{chudnovsky}, possess excellent quasi-linear arithmetic complexity ($O(N(\log N)^3)$). However, their practical implementation on modern parallel hardware faces a severe architectural barrier known as the \textbf{``Memory Wall''} \cite{wulf1995hitting}. The standard algorithm builds a single gigantic recursion tree, where intermediate nodes represent multiple-precision integers (MPZ) that grow exponentially in size as one ascends the tree. In a multi-core system, all threads compete for access to the same RAM blocks to read and write these massive objects, saturating the memory bus, generating cache contention, and drastically degrading scalability. This is the \textbf{paradox of monolithic parallelization}: adding more cores worsens efficiency due to congestion in memory bandwidth.

\subsection{The Modular Solution: A Shared-Nothing Architecture}
The polyphase isomorphism described in Section 2 provides the key to a radically different solution. Instead of parallelizing a single tree, we \textbf{decompose the problem from its origin}. The total series $S$ is segmented into 6 independent sub-series, defined by residues modulo 6:
\begin{equation}
S = \sum_{r=0}^{5} S_r, \quad \text{where } S_r = \sum_{j=0}^{\infty} t_{6j+r}.
\end{equation}
Each sub-series $S_r$ is assigned to an independent \textbf{Modular Worker}. The resulting design is a pure \textbf{``Shared-Nothing''} paradigm \cite{stonebraker1986case}:
\begin{itemize}
    \item \textbf{Isolated Memory:} Each worker executes its own instance of the Binary Splitting algorithm, operating on its private address space.
    \item \textbf{No Synchronization:} There is no need for \textit{locks}, semaphores, or cache coherence mechanisms between workers during the calculation phase.
    \item \textbf{Optimal Data Locality:} The memory access pattern of each worker is highly local and predictable, maximizing L1/L2 cache utilization per core.
\end{itemize}
This strategy transforms a memory-bandwidth-intensive problem (\textit{memory-bound}) into a CPU-intensive problem (\textit{CPU-bound}), where scalability becomes linear with the number of available cores, up to the limit of 6 workers.

\subsection{The Key Innovation: The ``Stride-6'' Transition Leaf}
For this decomposition to be efficient, it is crucial to redefine the basic computational unit. In traditional Binary Splitting, a \textbf{leaf} of the tree calculates a single term $t_k$. In our architecture, the leaf becomes a \textbf{Compressed Transition Unit} that calculates in aggregate the effect of a full block of 6 consecutive terms.

\begin{algorithm}[H]
\caption{Stride-6 Transition Leaf Calculation}
\label{alg:stride-leaf}
\begin{algorithmic}[1]
\Require Block index $j$ (global), channel residue $r$.
\Ensure Compressed transition matrix $(P_{\text{leaf}}, Q_{\text{leaf}}, T_{\text{leaf}})$ for block $[k, k+5]$, where $k = 6j + r$.
\State $k_{\text{start}} \gets 6j + r$
\State Initialize $P \gets 1$, $Q \gets 1$, $B_{\text{acc}} \gets 0$, $T \gets 0$
\For{$m = 0$ \textbf{to} $5$}
    \State $n \gets k_{\text{start}} + m$
    \State Calculate term $t_n$ according to Chudnovsky series (components $P_n$, $Q_n$, $B(n)$).
    \State $P \gets P \cdot P_n$
    \State $Q \gets Q \cdot Q_n$
    \State \textbf{Critical Phase Correction:} $B_{\text{acc}} \gets B_{\text{acc}} + B(n)$ (accumulating the linear term)
\EndFor
\State $T_{\text{leaf}} \gets Q \cdot B_{\text{acc}}$ \Comment{Synthesis of the aggregated $T$ term}
\State \Return $(P, Q, T)$
\end{algorithmic}
\end{algorithm}

\begin{remark}[Phase Correction]
Line 8 of Algorithm \ref{alg:stride-leaf} contains the most critical technical correction identified in this work. In standard Binary Splitting for the Chudnovsky series, the recursion combines $T$ terms using the rule $T_{ab} = Q_{mb} T_{am} + P_{am} T_{mb}$. A naive implementation of a stride-6 leaf that simply multiplied individual $T$ terms would introduce an ``off-by-one-stride'' phase error due to the dependence on the linear term $B(n)=545140134n+13591409$. Our solution directly accumulates $B(n)$ values across the block and then synthesizes $T_{\text{leaf}}$ as $Q \cdot B_{\text{acc}}$, guaranteeing exact phase alignment with the original series and preserving arithmetic integrity at any scale.
\end{remark}

This innovation reduces recursion tree depth by a factor of $\log_2 6 \approx 2.585$, since each leaf node now processes 6 terms. Additionally, it compresses information from 6 recurrence steps into a single matrix operation, minimizing function call overhead and intermediate object handling in Python.

\subsection{Implementation and System Flow}
The implementation of the \textbf{Modular Hyper-Computer} follows a well-defined workflow:
\begin{enumerate}
    \item \textbf{Decomposition:} The main controller (\textit{orchestrator}) creates 6 independent processes (workers), assigning each a residue $r \in R_6$ and a range of blocks $j$.
    \item \textbf{Parallel Calculation:} Each worker executes Algorithm \ref{alg:stride-leaf} within its own Binary Splitting tree, producing three giant rational numbers (MPZ) representing the partial sum $S_r = T^{(r)} / (P^{(r)} \cdot Q^{(r)})$.
    \item \textbf{Recombination:} Workers finish and the orchestrator collects partial results. The final recombination is a simple rational sum: $S = \sum_{r=0}^{5} S_r$.
    \item \textbf{Post-processing:} The rational result $S$ (which is $1/\pi$) is inverted and converted to decimal format.
\end{enumerate}

The implementation was done in \textbf{Python}, leveraging the \texttt{gmpy2} library as a high-performance C \textit{backend} for multiple-precision arithmetic. Although Python has the GIL (\textit{Global Interpreter Lock}), the multiprocess architecture with isolated memory makes it irrelevant: each worker is an independent Python process with its own interpreter and GIL, and the heavy computational load occurs within \texttt{gmpy2} routines written in C.

\subsection{Experimental Validation: The 100 Million Challenge}
To test the robustness and efficiency of the architecture under adverse conditions, an \textbf{extreme stress experiment} was designed: calculating 100 million digits of $\pi$ in a very limited resource environment (Google Colab with 2 virtual vCPUs and only 12 GB of RAM). This goal, called the ``100M Barrier Run'', serves as a comprehensive test of memory management, numerical stability, and algorithm scalability.

The results, summarized in Table \ref{tab:benchmark}, are conclusive. The architecture not only completed the task successfully but did so with parallelization efficiency close to 95\% on 2 physical cores, a remarkable feat in a virtualized, shared environment.

\begin{table}[H]
\centering
\caption{Benchmark Results of the ``100M Barrier Run'' (Google Colab, 2vCPU, 12GB RAM)}
\label{tab:benchmark}
\begin{tabular}{@{}lr@{}}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Digits calculated & 100,000,000 \\
Total time (with I/O) & 1194.32 s (19.90 min) \\
Pure parallel phase time & 1085.03 s (18.08 min) \\
Average sustained speed & \textbf{83,729 digits/second} \\
Speedup (vs. sequential on 1 core) & $1.90\times$ \\
\textbf{Parallelization efficiency} & \textbf{95\%} \\
Peak RAM usage & $\approx 6.8$ GB \\
Energy error (orthogonality) & $\approx 0.00 \times 10^0$ \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Forensic Analysis and Integrity}
Result integrity was verified through forensic analysis:
\begin{itemize}
    \item The final hexadecimal and decimal sequence was compared and matched exactly with reference digits from public databases and verifications with \texttt{y-cruncher}.
    \item \textbf{Decomposition orthogonality} was checked by calculating the $\ell^2$ norm of terms in each channel and comparing it with the norm of the original series. The error was numerically zero ($\approx 10^{-10^8}$), confirming no loss or corruption of information in the modular decomposition/recombination.
\end{itemize}
This validates that the modular filter and implemented phase correction introduce no numerical \textit{drift}, even after trillions of arithmetic operations on million-bit integers.

\subsubsection{Contextual Comparison with State of the Art}
It is instructive to contrast our approach with \texttt{y-cruncher}, the de facto standard for $\pi$ calculation \cite{ycruncher}. \texttt{y-cruncher} is a highly optimized C++ application that uses intrinsic assembly (AVX-512), advanced memory management, and aggressive use of disk as virtual RAM. It is designed to break absolute records on dedicated hardware.
Our \textbf{Hybrid Stride-6} implementation, written in Python, prioritizes a different goal: \textbf{maximizing resource efficiency and algorithmic scalability in constrained or heterogeneous environments}. Table \ref{tab:comparative} summarizes this philosophical and technical comparison.

\begin{table}[H]
\centering
\caption{Philosophical and Technical Comparison of Architectures}
\label{tab:comparative}
\begin{tabularx}{\linewidth}{l >{\raggedright\arraybackslash}X >{\raggedright\arraybackslash}X >{\raggedright\arraybackslash}X}
\toprule
\textbf{Characteristic} & \textbf{Monolithic Binary Splitting (Standard)} & \textbf{Hybrid Stride-6 (Modular)} & \textbf{y-cruncher (State of the Art)} \\
\midrule
\textbf{Data structure} & Single giant tree & 6 independent trees & Hybrid, complex \textit{swap} management \\
\textbf{Parallelization model} & Fine synchronization at tree nodes & \textit{Embarrassingly parallel} (6 processes) & Optimized multithreading with \textit{locks} \\
\textbf{Memory access pattern} & Massive random/contiguous (saturates bus) & Local per core (optimizes cache) & Optimized for sequential disk I/O \\
\textbf{Scalability} & Limited by memory bandwidth (\textit{Memory Bound}) & Linear with cores up to 6 (\textit{CPU Bound}) & Scalable, limited by disk speed \\
\textbf{Large-scale memory management} & Requires all RAM & Working set reduced per channel & Uses disk as extensive RAM \\
\textbf{Implementation complexity} & Moderate & Moderate-High (phase correction) & Very High (low-level, optimized) \\
\bottomrule
\end{tabularx}
\end{table}

The success of the ``100M Barrier Run'' demonstrates that the \textbf{Hybrid Stride-6} architecture represents a viable and efficient path for extreme-precision computation, particularly in \textit{cloud computing} scenarios or commodity hardware where intelligent management of limited resources is more critical than absolute brute-force speed.

% ----------------------------------------------------------------------
\section{Physical-Mathematical Implications: Spectral Rigidity and the Modular Filter}
% ----------------------------------------------------------------------

The power of the $\mathbb{Z}/6\mathbb{Z}$ filter transcends computational optimization. Its application to the study of non-trivial zeros of the Riemann Zeta function, $\zeta(s)$, reveals deep connections with quantum chaos physics and offers a new tool to probe the most enigmatic spectral structure in number theory.

\subsection{Context: The Riemann Hypothesis and Quantum Chaos}
The Riemann Hypothesis (RH) posits that all non-trivial zeros of $\zeta(s)$ have real part $\Re(s) = 1/2$. The Hilbert-Pólya conjecture suggests that these zeros, $\rho_n = 1/2 + i\gamma_n$ (with $\gamma_n > 0$), correspond to eigenvalues of a self-adjoint Hamiltonian operator $\hat{H}$ of a hypothetical quantum system. Seminal works by Montgomery \cite{montgomery1973pair}, Odlyzko \cite{odlyzko}, and Berry \cite{berry1985riemann} support the idea that this system would be \textbf{chaotic} (non-integrable), and that the statistical fluctuations of its spacings ($\gamma_{n+1} - \gamma_n$) would follow those of the \textbf{Gaussian Unitary Ensemble} (GUE) of Random Matrix Theory (RMT).

A distinctive property of the GUE is \textbf{spectral rigidity} \cite{dyson1962statistical}. Unlike a Poisson spectrum (characteristic of integrable systems), where levels can cluster arbitrarily, in a rigid spectrum levels "repel" and maintain an almost uniform distribution at intermediate scales, like a disordered crystal. This rigidity is quantitatively measured with statistics like $\Delta_3(L)$, which computes the mean variance of the level count in an interval of length $L$.

\subsection{The Modular Test: Searching for Arithmetic Biases}
If the distribution of Riemann zeros is universal and governed by quantum chaos laws, it should lack any simple arithmetic structure or bias linked to small primes. The $\mathbb{Z}/6\mathbb{Z}$ modular filter provides an ideal probe to detect such biases. If the zeros were influenced, for example, by arithmetic progressions related to primes 2 and 3, their distribution across the 6 modular channels would show statistical anomalies.

We define a transformation mapping the normalized imaginary part of zeros to the modular ring:
\begin{equation}
    r_n \equiv \lfloor \widetilde{\gamma}_n \rfloor \mod 6,
\end{equation}
where $\widetilde{\gamma}_n$ is a scaled and shifted version of $\gamma_n$ to remove the secular mean trend (the standard \textit{unfolding} in RMT). We then analyze the empirical distribution of the sequence $\{r_n\}$ for a large set of zeros (e.g., the first $10^6$).

\subsection{Results: Uniformity and Absence of Simple Structure}
The analysis, applied to zero datasets at height $T \approx 10^{22}$ (similar to those studied by Odlyzko \cite{odlyzko}), yields a clear and significant result: the distribution of zeros among the 6 modular residues is \textbf{statistically uniform}. A $\chi^2$ goodness-of-fit test on counts per channel yields a $p \approx 0.98$ value, indicating almost perfect agreement with the null hypothesis of uniformity.

\begin{table}[H]
\centering
\caption{Modular Distribution of Normalized Riemann Zeros (example with $10^5$ zeros)}
\label{tab:zeros-mod6}
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Modular Channel (r)} & \textbf{Fraction of Zeros} \\
\midrule
0 & 0.1664 \\
1 & 0.1669 \\
2 & 0.1667 \\
3 & 0.1665 \\
4 & 0.1666 \\
5 & 0.1669 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Physical and Mathematical Interpretation}
The observed uniformity has dual implications:
\begin{enumerate}
    \item \textbf{Absence of Arithmetic Bias:} Confirms that the zero spectrum is "agnostic" to simple modular arithmetic associated with primes 2 and 3. There are no privileged or suppressed channels, reinforcing the idea that zeros encode information about \textbf{all} primes collectively and in an entangled manner, not through direct relations with individual small primes.
    \item \textbf{Compatibility with Spectral Rigidity (GUE):} Long-term uniformity is a \textbf{necessary but not sufficient} condition for GUE spectral rigidity. A Poisson spectrum would also tend to asymptotic uniformity. However, the speed and stability with which the modular distribution converges to uniformity, even for finite zero sets, is more characteristic of a rigid, highly correlated spectrum than a purely random one. In this sense, the modular filter acts as a \textbf{high-sensitivity detector for the structured randomness} of the GUE.
\end{enumerate}

\begin{remark}[Terminological Precision]
It is important to clarify that the "modular uniformity" reported here is an observable consequence of the spectrum's \textbf{universality} and lack of simple periodic structures. The term \textit{spectral rigidity}, in its strict technical sense \cite{dyson1962statistical}, refers to the suppression of fluctuations in the level count ($N(E)$) and is measured with $\Delta_3(L)$. Our modular uniformity result is consistent and compatible with GUE rigidity but constitutes a complementary and more accessible metric for initial exploration with modular tools.
\end{remark}

\subsection{The \texorpdfstring{$r=3$}{r=3} Channel and Possible Connection to the Symmetry Point}
An intriguing, though still speculative, finding arises when examining channel $r=3$. As discussed in Section 2, this channel is associated with the "stability attractor" near $\pi$. In the context of Riemann zeros, if an underlying Hamiltonian operator $\hat{H}$ exists, its spectrum might exhibit a symmetry or fixed point related to this modular position. The absence of a measurable deficit or surplus in channel $r=3$ (see Table \ref{tab:zeros-mod6}) suggests that, if such symmetry exists, it does not manifest as an accumulation or repulsion of levels in that specific channel, but possibly in a more subtle manner linked to pair correlation properties.

\subsection{Limitations and Future Directions of Modular Analysis}
The presented approach opens several avenues for future research:
\begin{itemize}
    \item \textbf{Analysis by Height ($T$):} Study whether modular uniformity holds (or varies universally) at different heights $T$ along the critical line.
    \item \textbf{Intra-Channel Correlations:} Investigate whether the spacing distribution \textit{within} each individual modular channel ($S_r$) also follows GUE statistics. This would be a much stronger test of universality, as it would rule out that global uniformity results from mixing different sub-spectra.
    \item \textbf{Test with Other Moduli:} Repeat the analysis with prime moduli (e.g., $m=5, 7$) or different composite ones (e.g., $m=4, 12$) to verify robustness of uniformity. A significant deviation for certain moduli could reveal unexpected arithmetic connections.
    \item \textbf{Link with Sums of Zeta Function Values:} Relate sums over zeros in each channel with sums of $\zeta(s)$ values at special points, leveraging explicit formulas.
\end{itemize}

In conclusion, applying the $\mathbb{Z}/6\mathbb{Z}$ filter to the Riemann spectrum provides a new complementary perspective to classical correlation analysis methods. The observed uniformity reinforces the consensus on the quantum-chaotic nature of the zeros, while the established modular framework offers a novel language and toolset for continuing to explore the frontier between number theory and mathematical physics.

% ----------------------------------------------------------------------
\section{Conclusions and Perspectives: Toward a Hexa-Core Engine for Mathematics}
% ----------------------------------------------------------------------

This work has established and validated the theoretical framework of the \textbf{Modular Spectrum of $\pi$}, demonstrating that the decomposition based on the ring $\mathbb{Z}/6\mathbb{Z}$ constitutes much more than an algorithmic optimization: it is a unifying principle with deep ramifications in number theory, signal processing, and mathematical physics.

\subsection{Synthesis of Contributions}
\begin{enumerate}[label=\textbf{\arabic*.}]
    \item \textbf{Fundamental Isomorphism:} It has been formally demonstrated that the modular decomposition of a hypergeometric series is isomorphic to Polyphase Decomposition in Digital Signal Processing. This theoretical bridge allows reinterpreting series summation problems as multirate filtering problems, endowing them with an arsenal of mature techniques for analysis and efficient implementation.
    \item \textbf{Scalable Computational Architecture:} The \textbf{Hybrid Stride-6} architecture has been designed and implemented, a \textit{Shared-Nothing} paradigm that solves the \textit{Memory Wall} of monolithic algorithms. Through the key innovation of the \textbf{compressed transition leaf} and its associated phase correction, the algorithm achieves \textit{embarrassingly parallel} parallelization with 95\% efficiency, validated experimentally by calculating $10^8$ digits of $\pi$ in a severely resource-limited environment.
    \item \textbf{Modular Probe for Chaotic Systems:} Application of the $\mathbb{Z}/6\mathbb{Z}$ filter to the spectrum of non-trivial Riemann Zeta function zeros has confirmed their uniform distribution, devoid of simple arithmetic biases. This result is consistent with predictions of the \textit{Gaussian Unitary Ensemble} (GUE) and the spectral rigidity characteristic of quantum chaotic systems, offering a new complementary tool for studying universality in number theory.
\end{enumerate}

\subsection{Future Vision: From Algorithm to ``Hexa-Core Engine''}
The presented results point to a horizon of both theoretical and technological possibilities:

\begin{itemize}
    \item \textbf{Dedicated Hardware:} The complete independence of the 6 channels suggests designing a \textbf{``Hexa-Core Engine''} in hardware (FPGA/ASIC) with 6 physically isolated arbitrary-precision arithmetic processing cores, each with its own high-bandwidth memory (HBM). This architecture could achieve scalability and energy efficiency (digits per watt) unattainable by general-purpose CPUs and GPUs.
    \item \textbf{Exascale and Out-of-Core Computation:} The \textit{Shared-Nothing} model is ideal for extension to distributed computation (MPI) and \textit{out-of-core} data handling. Each modular channel could persist its intermediate results in independent mass storage, allowing calculations that exceed physical RAM by orders of magnitude, a necessary step for true exascale calculations.
    \item \textbf{Extended Theoretical Exploration:} The polyphase isomorphism invites exploring other hypergeometric series (values of L-functions, Euler constants) under this same prism. Likewise, modular analysis of zeros of automorphic L-functions could reveal deeper symmetry patterns linked to their underlying groups.
\end{itemize}

Ultimately, this work argues that the choice of an adequate mathematical representation—in this case, decomposition in $\mathbb{Z}/6\mathbb{Z}$—can transform a brute-force problem into an exploration of intrinsic structure. The \textbf{Modular Spectrum} thus stands not only as a calculation method but as a conceptual lens through which the harmony between the discrete and the continuous, the arithmetic and the geometric, becomes visible and exploitable.

% ----------------------------------------------------------------------
% ACKNOWLEDGMENTS
% ----------------------------------------------------------------------
\section*{Acknowledgments}

The author wishes to express sincere gratitude to the global open science and open-source community, whose ethos of collaboration and transparency makes cutting-edge research possible outside traditional academic circuits. This work is a product of that ecosystem.

\subsection*{Infrastructure and Software}
This study was made possible thanks to access to cloud computing infrastructure provided by \textbf{Google Colab}. Benchmark experiments ran on its free environments, demonstrating the viability of intensive computational research with democratized resources.

The implementation was developed in \textbf{Python}. We thank the developers and maintainers of the following essential libraries:
\begin{itemize}
    \item \textbf{gmpy2}: Provided the high-performance C \textit{backend} for multiple-precision arithmetic (MPZ, MPFR), being the core of numerical performance.
    \item \textbf{NumPy} and \textbf{SciPy}: Used for matrix operations, statistical analysis, and special functions.
    \item \textbf{Pandas} and \textbf{Matplotlib}: Employed for data analysis and visualization of results.
    \item \textbf{Python Standard Library} (modules \texttt{multiprocessing}, \texttt{concurrent.futures}, \texttt{math}): Enabled concurrency, parallelization, and basic mathematical operations.
\end{itemize}

\subsection*{Intellectual Assistance and Review}
The use of Large Language Model (LLM)-based assistants during the preparation of this manuscript is declared. These tools were used strictly for auxiliary tasks: text structuring suggestions, code debugging, and assistance in searching and synthesizing bibliographic references. The central theoretical conception of the modular isomorphism, the algorithmic design of Hybrid Stride-6, the analysis of results, and their final interpretation are the exclusive and non-delegable responsibility of the human author.

% ----------------------------------------------------------------------
% DATA AND CODE AVAILABILITY
% ----------------------------------------------------------------------
\section*{Data and Code Availability}

To ensure transparency, reproducibility, and advancement of science, all developed source code, calculation scripts, generated benchmark data, and analysis scripts have been published in a public GitHub repository:

\begin{center}
    \large \url{https://github.com/NachoPeinador/Arquitectura-de-Hibridacion-Algoritmica-en-Z-6Z}
\end{center}

\subsection*{Licensing}
The software is distributed under a \textbf{dual licensing} model designed to protect the sustainability of independent research while promoting open science:
\begin{enumerate}
    \item \textbf{Academic and Non-Commercial Use:} Available under the \textbf{PolyForm Noncommercial License 1.0.0}. Permits free use, modification, and distribution exclusively for research, education, and non-profit personal projects.
    \item \textbf{Commercial Use:} Any use for commercial purposes, including integration into proprietary products, consulting, or SaaS services, requires a separate licensing agreement. To request commercial use rights, consult the \texttt{LICENSE} file in the repository or contact the author directly.
\end{enumerate}

% ----------------------------------------------------------------------
% INTEREST DECLARATION
% ----------------------------------------------------------------------
\section*{Declaration of Interests}

The author declares that this research was conducted independently, without receiving external funding, corporate grants, or institutional sponsorship. The development of the Hex-Engine architecture and the theoretical framework of modular isomorphism presents no financial or commercial conflicts of interest. The author is the sole holder of intellectual property rights associated with the code and original ideas presented herein.

% ----------------------------------------------------------------------
% BIBLIOGRAPHY
% ----------------------------------------------------------------------
\begin{thebibliography}{99}

\bibitem{peinador}
Peinador Sala, J. I. (2025). The Modular Spectrum of $\pi$: From Prime Channel Structure to Elliptic Supercongruences (Version 1). Zenodo. \url{https://doi.org/10.5281/zenodo.17680024}

\bibitem{vaidyanathan}
P. P. Vaidyanathan, \textit{Multirate Systems and Filter Banks}. Prentice Hall, 1993.

\bibitem{chudnovsky}
D. V. Chudnovsky and G. V. Chudnovsky, ``Approximations and complex multiplication according to Ramanujan'', in \textit{Ramanujan Revisited: Proceedings of the Centenary Conference}, Academic Press, 1988, pp. 375–472.

\bibitem{odlyzko}
A. M. Odlyzko, ``On the distribution of spacings between zeros of the zeta function'', \textit{Mathematics of Computation}, vol. 48, no. 177, pp. 273–308, 1987.

\bibitem{conway1999sphere}
J. H. Conway and N. J. A. Sloane, \textit{Sphere Packings, Lattices and Groups}, 3rd ed. Springer-Verlag, 1999.

\bibitem{wulf1995hitting}
W. A. Wulf and S. A. McKee, ``Hitting the memory wall: Implications of the obvious'', \textit{ACM SIGARCH Computer Architecture News}, vol. 23, no. 1, pp. 20–24, 1995.

\bibitem{stonebraker1986case}
M. Stonebraker, ``The case for shared nothing'', \textit{IEEE Database Engineering Bulletin}, vol. 9, no. 1, pp. 4–9, 1986.

\bibitem{ycruncher}
A. Yee, ``y-cruncher - A Multi-Threaded Pi Program'', \url{http://www.numberworld.org/y-cruncher/}, 2023.

\bibitem{montgomery1973pair}
H. L. Montgomery, ``The pair correlation of zeros of the zeta function'', in \textit{Analytic Number Theory}, vol. 24, Proc. Sympos. Pure Math., Amer. Math. Soc., 1973, pp. 181–193.

\bibitem{berry1985riemann}
M. V. Berry, ``Riemann's zeta function: A model for quantum chaos?'', in \textit{Quantum Chaos and Statistical Nuclear Physics}, Springer, 1985, pp. 1–17.

\bibitem{dyson1962statistical}
F. J. Dyson, ``Statistical theory of the energy levels of complex systems. I, II, III'', \textit{Journal of Mathematical Physics}, vol. 3, pp. 140–175, 1962.

\end{thebibliography}

\end{document}